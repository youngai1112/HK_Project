{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import hanja\n",
    "from hanja import hangul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-win_amd64.whl (438.0 MB)\n",
      "     -------------------------------------- 438.0/438.0 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     -------------------------------------- 895.7/895.7 KB 2.8 MB/s eta 0:00:00\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-win_amd64.whl (3.4 MB)\n",
      "     ---------------------------------------- 3.4/3.4 MB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting tensorboard<2.9,>=2.8Note: you may need to restart the kernel to use updated packages.\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=6448329050911b322a2ddec60d689f9952506d8807077833aadd1619959f404f\n",
      "  Stored in directory: c:\\users\\easya\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: tf-estimator-nightly, termcolor, tensorboard-plugin-wit, libclang, keras, flatbuffers, tensorflow-io-gcs-filesystem, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras-preprocessing, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Using cached konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.3.0-cp39-cp39-win_amd64.whl (362 kB)\n",
      "     -------------------------------------- 362.6/362.6 KB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from konlpy) (1.20.3)\n",
      "Installing collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hanja\n",
      "  Using cached hanja-0.13.3.tar.gz (120 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyyaml==5.1.2\n",
      "  Using cached PyYAML-5.1.2.tar.gz (265 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pytest in c:\\users\\easya\\anaconda3\\lib\\site-packages (from hanja) (6.2.4)\n",
      "Requirement already satisfied: pytest-cov in c:\\users\\easya\\anaconda3\\lib\\site-packages (from hanja) (3.0.0)\n",
      "Requirement already satisfied: coveralls in c:\\users\\easya\\anaconda3\\lib\\site-packages (from hanja) (3.3.1)\n",
      "Requirement already satisfied: coverage!=6.0.*,!=6.1,!=6.1.1,<7.0,>=4.1 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from coveralls->hanja) (6.3.2)\n",
      "Requirement already satisfied: docopt>=0.6.1 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from coveralls->hanja) (0.6.2)\n",
      "Requirement already satisfied: requests>=1.0.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from coveralls->hanja) (2.26.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (21.2.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (21.0)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (1.10.0)\n",
      "Requirement already satisfied: toml in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (0.10.2)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\easya\\anaconda3\\lib\\site-packages (from pytest->hanja) (0.4.4)\n",
      "Requirement already satisfied: tomli in c:\\users\\easya\\anaconda3\\lib\\site-packages (from coverage!=6.0.*,!=6.1,!=6.1.1,<7.0,>=4.1->coveralls->hanja) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests>=1.0.0->coveralls->hanja) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests>=1.0.0->coveralls->hanja) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests>=1.0.0->coveralls->hanja) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from requests>=1.0.0->coveralls->hanja) (2021.10.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\easya\\anaconda3\\lib\\site-packages (from packaging->pytest->hanja) (3.0.4)\n",
      "Building wheels for collected packages: hanja, pyyaml\n",
      "  Building wheel for hanja (setup.py): started\n",
      "  Building wheel for hanja (setup.py): finished with status 'done'\n",
      "  Created wheel for hanja: filename=hanja-0.13.3-py3-none-any.whl size=125964 sha256=571490c464fbd6ddfd94f74e6a54ee2e0055cfa29d0b8ed554dfb590e22a6301\n",
      "  Stored in directory: c:\\users\\easya\\appdata\\local\\pip\\cache\\wheels\\98\\5c\\a3\\8f482b30633a7466c0bc9fb748e59b2fdcb67573cf3600c73f\n",
      "  Building wheel for pyyaml (setup.py): started\n",
      "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp39-cp39-win_amd64.whl size=44112 sha256=515fad9dad71f2b33b5032aa1c2793a465c794532c9a81a6b22354cc77c11e85\n",
      "  Stored in directory: c:\\users\\easya\\appdata\\local\\pip\\cache\\wheels\\93\\72\\1b\\db6b10e2b46c76704d0eb0716d72091146e539648f6b164bae\n",
      "Successfully built hanja pyyaml\n",
      "Installing collected packages: pyyaml, hanja\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "Successfully installed hanja-0.13.3 pyyaml-5.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "# pip install hanja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58439</th>\n",
       "      <td>20151019</td>\n",
       "      <td>[특징주]제주반도체, 美·中 대규모 투자유치에 '上'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58440</th>\n",
       "      <td>20151019</td>\n",
       "      <td>[반도체] 2016 반도체 투자 감소 예상 - 미래</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58441</th>\n",
       "      <td>20151019</td>\n",
       "      <td>제주반도체, '해외투자유치설' 조회공시 요구</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                          title\n",
       "58439  20151019  [특징주]제주반도체, 美·中 대규모 투자유치에 '上'\n",
       "58440  20151019   [반도체] 2016 반도체 투자 감소 예상 - 미래\n",
       "58441  20151019       제주반도체, '해외투자유치설' 조회공시 요구"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdata = pd.read_csv(\"../data/Newsfile3.csv\", encoding='euc-kr')\n",
    "newsdata.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58442 entries, 0 to 58441\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   date    58442 non-null  int64 \n",
      " 1   title   58442 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 913.3+ KB\n"
     ]
    }
   ],
   "source": [
    "newsdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     0\n",
       "title    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "newsdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. train, test dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(newsdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>20211018</td>\n",
       "      <td>\"車반도체 위기 언제든 재발, 근본 대책 마련해야\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34496</th>\n",
       "      <td>20190413</td>\n",
       "      <td>홍남기, 中재정부장 면담…“반도체 반독점 조사ㆍ단체관광 배려 요청”</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                  title\n",
       "5922   20211018           \"車반도체 위기 언제든 재발, 근본 대책 마련해야\"\n",
       "34496  20190413  홍남기, 中재정부장 면담…“반도체 반독점 조사ㆍ단체관광 배려 요청”"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data 확인\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43831, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data shape 확인\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15076</th>\n",
       "      <td>20210331</td>\n",
       "      <td>자동차 이어 IT·가전까지… 전방위로 번지는 반도체 공급 대란</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20220307</td>\n",
       "      <td>러·우크라 사태 반도체 공급망 우려↑… 삼전·SK하이닉스 '동반 하락'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                    title\n",
       "15076  20210331       자동차 이어 IT·가전까지… 전방위로 번지는 반도체 공급 대란\n",
       "282    20220307  러·우크라 사태 반도체 공급망 우려↑… 삼전·SK하이닉스 '동반 하락'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data 확인\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14611, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data shape 확인\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한글, 영어, 숫자, 한자 이외의 문자열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"title\"] = train_data[\"title\"].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣|A-Za-z|一-龥 ]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한자가 들어간 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hanja_data = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('美', 2092), ('中', 1872), ('車', 1352), ('日', 1096), ('韓', 943)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('[一-龥]')\n",
    "# 한자 리스트 확인\n",
    "hanja_list = train_hanja_data[\"title\"].str.findall(pattern).sum()\n",
    "# 빈도수가 높은 한자 체크\n",
    "Counter(hanja_list).most_common()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['車', '中', '美', '株', '日', '比', '硏', '韓', '發', '來', '克', '兆', '新', '政', '證', '非', '文', '外', '會', '協', '與', '好', '前', '苦', '高', '史', '亞', '人', '英', '月', '弗', '三', '電', '社', '對', '益', '印', '價', '訪', '力', '企', '獨', '臺', '道', '行', '委', '年', '低', '和', '課', '先', '後', '夢', '大', '無', '佛', '銀', '靑', '孝', '水', '問', '軍', '反', '戰', '全', '乙', '週', '市', '癌', '說', '華', '法', '式', '超', '亂', '民', '官', '恨', '弱', '尹', '稅', '甲', '論', '者', '故', '風', '訴', '業', '産', '純', '功', '逆', '本', '通', '學', '富', '强', '脫', '現', '伊', '枯', '死', '重', '加', '辛', '談', '事', '萬', '公', '種', '難', '西', '安', '告', '上', '名', '家', '氣', '光', '州', '場', '號', '北', '販', '禁', '檢', '洪', '向', '島', '王', '次', '自', '害', '有', '飛', '油', '化', '國', '順', '毒', '選', '濠', '路', '錢', '材', '設', '異', '石', '展', '街', '烹', '裝', '喜', '悲', '多', '曰', '火', '內', '下', '船', '守', '城', '熱', '報', '信', '賞', '災', '星', '鐵', '經', '女', '共', '塞', '翁', '之', '馬', '崔', '母', '投', '心', '燈', '刮', '目', '相', '神', '用']\n"
     ]
    }
   ],
   "source": [
    "# 한자 중복값 제거 확인\n",
    "new_list = []\n",
    "for i in hanja_list:\n",
    "    if i not in new_list:\n",
    "        new_list.append(i)\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `한자 -> 한글로 대체`\n",
    "    - 뉴스 제목에 사용되는 한자들은 의미를 축약한 한 글자로 구성된 한자가 많은 것으로 추측됨\n",
    "    - 한자 -> 한글로 단순 번역하는 방법을 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"title\"] = train_data[\"title\"].apply(lambda x: hanja.translate(x, \"substitution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>20211018</td>\n",
       "      <td>차반도체 위기 언제든 재발 근본 대책 마련해야</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34496</th>\n",
       "      <td>20190413</td>\n",
       "      <td>홍남기 중재정부장 면담반도체 반독점 조사단체관광 배려 요청</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29602</th>\n",
       "      <td>20190815</td>\n",
       "      <td>반도체 소재 등 개 품목 기술개발에 억 조기 투입</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                             title\n",
       "5922   20211018         차반도체 위기 언제든 재발 근본 대책 마련해야\n",
       "34496  20190413  홍남기 중재정부장 면담반도체 반독점 조사단체관광 배려 요청\n",
       "29602  20190815       반도체 소재 등 개 품목 기술개발에 억 조기 투입"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한글, 영어, 숫자, 한자 이외의 문자열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"title\"] = test_data[\"title\"].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣|A-Za-z|一-龥 ]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hanja_data = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('美', 697), ('中', 638), ('車', 469), ('日', 346), ('韓', 335)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('[一-龥]')\n",
    "# 한자 리스트 확인\n",
    "hanja_list2 = test_hanja_data[\"title\"].str.findall(pattern).sum()\n",
    "# 빈도수가 높은 한자 체크\n",
    "Counter(hanja_list2).most_common()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한자가 들어간 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['硏', '韓', '株', '高', '車', '美', '中', '日', '行', '比', '外', '兆', '證', '好', '文', '三', '電', '全', '克', '訴', '亞', '尹', '親', '發', '對', '新', '獨', '大', '社', '銀', '式', '非', '賞', '來', '靑', '無', '英', '協', '富', '反', '稅', '弗', '價', '內', '企', '故', '訪', '結', '氣', '年', '人', '産', '學', '强', '委', '延', '月', '風', '紙', '油', '化', '朴', '輸', '差', '益', '前', '脫', '臺', '與', '敵', '水', '北', '弱', '向', '居', '安', '思', '危', '戰', '號', '色', '國', '昌', '上', '面', '有', '他', '位', '相', '佛', '事', '萬', '光', '格', '場', '王', '重', '檢', '勝', '談', '用', '說', '市', '苦']\n"
     ]
    }
   ],
   "source": [
    "# 한자 중복값 제거 확인\n",
    "new_list = []\n",
    "for i in hanja_list2:\n",
    "    if i not in new_list:\n",
    "        new_list.append(i)\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `한자 -> 한글로 대체`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"title\"] = test_data[\"title\"].apply(lambda x: hanja.translate(x, \"substitution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15076</th>\n",
       "      <td>20210331</td>\n",
       "      <td>자동차 이어 IT가전까지 전방위로 번지는 반도체 공급 대란</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20220307</td>\n",
       "      <td>러우크라 사태 반도체 공급망 우려 삼전SK하이닉스 동반 하락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56453</th>\n",
       "      <td>20160401</td>\n",
       "      <td>삼성전자 지난해 성적표 반도체DPTV휴대전화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                              title\n",
       "15076  20210331   자동차 이어 IT가전까지 전방위로 번지는 반도체 공급 대란\n",
       "282    20220307  러우크라 사태 반도체 공급망 우려 삼전SK하이닉스 동반 하락\n",
       "56453  20160401          삼성전자 지난해 성적표 반도체DPTV휴대전화 "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 명사만 추출한 컬럼 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 단계완료\n",
      "2000 단계완료\n",
      "4000 단계완료\n",
      "6000 단계완료\n",
      "8000 단계완료\n",
      "10000 단계완료\n",
      "12000 단계완료\n",
      "14000 단계완료\n",
      "16000 단계완료\n",
      "18000 단계완료\n",
      "20000 단계완료\n",
      "22000 단계완료\n",
      "24000 단계완료\n",
      "26000 단계완료\n",
      "28000 단계완료\n",
      "30000 단계완료\n",
      "32000 단계완료\n",
      "34000 단계완료\n",
      "36000 단계완료\n",
      "38000 단계완료\n",
      "40000 단계완료\n",
      "42000 단계완료\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "n_ = []\n",
    "title_rename = []\n",
    "for i in range(len(train_data)):\n",
    "    if (i % 2000 == 0):\n",
    "        print(i, \"단계완료\")\n",
    "    n_.append(' '.join(okt.nouns(train_data.iloc[i][\"title\"])))\n",
    "\n",
    "\n",
    "# 명사 추출 컬럼 \n",
    "train_data[\"nouns\"] = n_\n",
    "\n",
    "# empty space가 아닌 nouns 컬럼만 train_data에 저장\n",
    "train_data = train_data[train_data[\"nouns\"] != ''] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>20211018</td>\n",
       "      <td>차반도체 위기 언제든 재발 근본 대책 마련해야</td>\n",
       "      <td>차 반도체 위기 언제 재발 근본 대책 마련</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34496</th>\n",
       "      <td>20190413</td>\n",
       "      <td>홍남기 중재정부장 면담반도체 반독점 조사단체관광 배려 요청</td>\n",
       "      <td>홍 중재 정부 면담 반도체 독점 조사 단체 관광 배려 요청</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29602</th>\n",
       "      <td>20190815</td>\n",
       "      <td>반도체 소재 등 개 품목 기술개발에 억 조기 투입</td>\n",
       "      <td>반도체 소재 등 개 품목 기술 개발 억 조기 투입</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                             title  \\\n",
       "5922   20211018         차반도체 위기 언제든 재발 근본 대책 마련해야   \n",
       "34496  20190413  홍남기 중재정부장 면담반도체 반독점 조사단체관광 배려 요청   \n",
       "29602  20190815       반도체 소재 등 개 품목 기술개발에 억 조기 투입   \n",
       "\n",
       "                                  nouns  \n",
       "5922            차 반도체 위기 언제 재발 근본 대책 마련  \n",
       "34496  홍 중재 정부 면담 반도체 독점 조사 단체 관광 배려 요청  \n",
       "29602       반도체 소재 등 개 품목 기술 개발 억 조기 투입  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 단계완료\n",
      "2000 단계완료\n",
      "4000 단계완료\n",
      "6000 단계완료\n",
      "8000 단계완료\n",
      "10000 단계완료\n",
      "12000 단계완료\n",
      "14000 단계완료\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "n_ = []\n",
    "title_rename = []\n",
    "for i in range(len(test_data)):\n",
    "    if (i % 2000 == 0):\n",
    "        print(i, \"단계완료\")\n",
    "    n_.append(' '.join(okt.nouns(test_data.iloc[i][\"title\"])))\n",
    "\n",
    "\n",
    "# 명사 추출 컬럼 \n",
    "test_data[\"nouns\"] = n_\n",
    "\n",
    "# empty space가 아닌 nouns 컬럼만 test_data에 저장\n",
    "test_data = test_data[test_data[\"nouns\"] != ''] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15076</th>\n",
       "      <td>20210331</td>\n",
       "      <td>자동차 이어 IT가전까지 전방위로 번지는 반도체 공급 대란</td>\n",
       "      <td>자동차 가전 전방 위로 번지 반도체 공급 대란</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20220307</td>\n",
       "      <td>러우크라 사태 반도체 공급망 우려 삼전SK하이닉스 동반 하락</td>\n",
       "      <td>러우크 사태 반도체 공급망 우려 삼전 하이닉스 동반 하락</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56453</th>\n",
       "      <td>20160401</td>\n",
       "      <td>삼성전자 지난해 성적표 반도체DPTV휴대전화</td>\n",
       "      <td>삼성 전자 지난해 성적표 반도체 휴대전화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                              title  \\\n",
       "15076  20210331   자동차 이어 IT가전까지 전방위로 번지는 반도체 공급 대란   \n",
       "282    20220307  러우크라 사태 반도체 공급망 우려 삼전SK하이닉스 동반 하락   \n",
       "56453  20160401          삼성전자 지난해 성적표 반도체DPTV휴대전화    \n",
       "\n",
       "                                 nouns  \n",
       "15076        자동차 가전 전방 위로 번지 반도체 공급 대란  \n",
       "282    러우크 사태 반도체 공급망 우려 삼전 하이닉스 동반 하락  \n",
       "56453           삼성 전자 지난해 성적표 반도체 휴대전화  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에러내용 : JVMNotFoundException: No JVM shared library file (jvm.dll) found.\n",
    "    - 참고 : https://stricky.tistory.com/398"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('64bit', 'WindowsPE')\n"
     ]
    }
   ],
   "source": [
    "# python bit 확인\n",
    "import platform\n",
    "print(platform.architecture())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오라클 JDK 다운로드 사이트 :  https://www.oracle.com/java/technologies/downloads/#java8\n",
    "\n",
    "- 설치 경로 확인 > 시스템 환경 변수에 추가 > 변수이름 `JAVA_HOME`으로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "237dfbe96289c26a34bb3817ed9a5dda5a1f28f78dcc25894f58473fa7732fcf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 컨텐츠 기반 모델\n",
    "1. 정의\n",
    "    - 참고 : recommendation systems handbook(Francesco Ricci)\n",
    "    - 컨텐츠 기반 추천시스템은 사용자가 이전에 구매한 상품중에서 좋아하는 상품들과 유사한 상품들을 추천하는 방법\n",
    "2. Represented Items\n",
    "    - Items을 벡터 형태로 표현. 도메인에 따라 다른 방법이 적용\n",
    "    - `텍스트` -> TF-IDF, BERT, Word2Vec, CounterVectorizer(빈도수 기반) 자연어처리 모델을 통해 벡터화 가능\n",
    "    - `이미지` -> CNN, VGG (딥러닝 기반 모델) 벡터화 가능\n",
    "    - 아이템 > 벡터화 > 벡터들간의 유사도를 계산 > 벡터1부터 N까지 자신과 유사한 벡터를 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 유사도 함수\n",
    "- 참고 : https://cmry.github.io/notes/euclidean-v-cosine\n",
    "- 참고 : https://bab2min.tistory.com/566\n",
    "1. 유클리디안 유사도\n",
    "    - 문서간의 유사도를 계산\n",
    "    - 유클리디안 유사도 = 1 / (유클리디안 거리 + 1e-05)\n",
    "    - 장점 : 계산하기가 쉬움\n",
    "        - 각각의 요소 (컬럼 하나하나)가 크기에 민감하거나 중요한 경우 효과를 볼 수 있다. \n",
    "    - 단점 : p와 q의 분포가 다르거나 범위가 다른 경우에 상관성을 놓침\n",
    "2. 코사인 유사도\n",
    "    - 문서간의 유사도를 계산\n",
    "    - 장점 : 벡터의 크기가 중요하지 않은 경우에 거리를 측정하기 위한 메트릭으로 사용\n",
    "        - 예) 문서 내에서 단어의 빈도수\n",
    "        -   문서들의 길이가 고르지 않더라도 문서내에서 얼마나 나왔는지라는 비율을 확인하기 때문에 상관없음\n",
    "    - 단점 : 벡터의 크기가 중요한 경우에 대해서 잘 작동하지 않음\n",
    "3. 피어슨 유사도\n",
    "    - 문서간의 유사도를 계산\n",
    "4. 자카드 유사도\n",
    "    - 문서간의 유사도를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. 자연어 처리 알고리즘 - TF-IDF\n",
    "- 참고 : https://wikidocs.net/31698\n",
    "1. 정의\n",
    "    - TF-IDF는 특정 문서 내에 특정 단어가 얼마나 자주 등장하는지를 의미하는 **단어 빈도(TF)**\n",
    "    -   전체 문서에서 특정 단어가 얼마나 자주 등장하는지를 의미하는 역문서 빈도(DF)\n",
    "    -   \"다른 문서에는 등장하지 않지만 특정 문서에서만 자주 등장하는 단어\"를 찾아서 문서 내 가중치를 계산하는 방법\n",
    "2. 용도 \n",
    "    - 문서의 핵심어를 추출, 문서들 사시의 유사도를 계산, 검색 결과의 중요도를 정하는 작업 등에 활용\n",
    "3. TF, DF, IDF 정의\n",
    "    - `TF`(d, t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
    "    - `DF`(t) : 특정 단어 t가 등장한 문서의 수\n",
    "    - `IDF`(d, t) : DF(t)에 반비례하는 수\n",
    "    - TF(d,t) * IDF(d,t) = TF-IDF(d,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2. TF-IDF를 사용하는 이유\n",
    "- 참고 : https://chan-lab.tistory.com/24\n",
    "1. Item이라는 컨텐츠를 벡터로 \"Feature Extract\" 과정을 수행해준다.\n",
    "2. 빈도수를 기반으로 많이 나오는 중요한 단어들을 잡아준다. => Counter Vectorizer\n",
    "3. Counter Vectorizer는 단순 빈도만을 계산\n",
    "    - 조사, 관사처럼 의미는 없지만 문장에 많이 등장하는 단어들도 높게 쳐주는 한계가 있음\n",
    "    - 이러한 단어들에는 패널티를 줘서 적절하게 중요한 단어만을 잡아내는 것이 TF-IDF 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-3. TF-IDF의 장점과 단점\n",
    "1. 장점\n",
    "    - 직관적인 해석이 가능\n",
    "2. 단점\n",
    "    - 대규모 말뭉치를 다룰 때 메모리 상의 문제가 발생\n",
    "    - 높은 차원을 가짐\n",
    "    - 매우 sparse한 형태의 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TF-IDF 코드 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [\n",
    "    '먹고 싶은 사과',\n",
    "    '먹고 싶은 바나나',\n",
    "    '길고 노란 바나나 바나나',\n",
    "    '저는 과일이 좋아요'\n",
    "]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 Counter Vectorizer 형태로 변형\n",
    "countvect = vect.fit_transform(docs)\n",
    "countvect   # 4 * 9 : 4개의 문서에 9개의 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toarray()를 통해서 문장이 Vector 형태의 값을 얻을 수 있음\n",
    "# 하지만, 각 인덱스와 컬럼이 무엇을 의미하는지에 대해서는 알 수가 없음\n",
    "# sparse matrix -> numpy\n",
    "countvect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'먹고': 3,\n",
       " '싶은': 6,\n",
       " '사과': 5,\n",
       " '바나나': 4,\n",
       " '길고': 1,\n",
       " '노란': 2,\n",
       " '저는': 7,\n",
       " '과일이': 0,\n",
       " '좋아요': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict 형태로, 각각의 단어가 인덱스를 가지고 있다는 것을 알 수 있음\n",
    "# 즉, 각 단어가 어떤 컬럼에 위치하는지를 알 수 있다. \n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted라는 함수를 통해서 단어를 정렬\n",
    "# value 값을 기준으로 순서대로 정렬\n",
    "sorted(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "문서1    0   0   0   1    0   1   1   0    0\n",
       "문서2    0   0   0   1    1   0   1   0    0\n",
       "문서3    0   1   1   0    2   0   0   0    0\n",
       "문서4    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "countvect_df = pd.DataFrame(countvect.toarray(), columns=sorted(vect.vocabulary_))\n",
    "countvect_df.index = [\"문서1\", \"문서2\", \"문서3\", \"문서4\"]\n",
    "countvect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.66666667, 0.        , 0.        ],\n",
       "       [0.66666667, 1.        , 0.47140452, 0.        ],\n",
       "       [0.        , 0.47140452, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코사인 유사도를 사용하여 유사도 측정\n",
    "#   0번 문서는 1번과 유사하다는 결론을 얻을 수 있다. \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(countvect_df, countvect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

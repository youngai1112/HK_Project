{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 컨텐츠 기반 모델\n",
    "1. 정의\n",
    "    - 참고 : recommendation systems handbook(Francesco Ricci)\n",
    "    - 컨텐츠 기반 추천시스템은 사용자가 이전에 구매한 상품중에서 좋아하는 상품들과 유사한 상품들을 추천하는 방법\n",
    "2. Represented Items\n",
    "    - Items을 벡터 형태로 표현. 도메인에 따라 다른 방법이 적용\n",
    "    - `텍스트` -> TF-IDF, BERT, Word2Vec, CounterVectorizer(빈도수 기반) 자연어처리 모델을 통해 벡터화 가능\n",
    "    - `이미지` -> CNN, VGG (딥러닝 기반 모델) 벡터화 가능\n",
    "    - 아이템 > 벡터화 > 벡터들간의 유사도를 계산 > 벡터1부터 N까지 자신과 유사한 벡터를 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 유사도 함수\n",
    "- 참고 : https://cmry.github.io/notes/euclidean-v-cosine\n",
    "- 참고 : https://bab2min.tistory.com/566\n",
    "1. 유클리디안 유사도\n",
    "    - 문서간의 유사도를 계산\n",
    "    - 유클리디안 유사도 = 1 / (유클리디안 거리 + 1e-05)\n",
    "    - 장점 : 계산하기가 쉬움\n",
    "        - 각각의 요소 (컬럼 하나하나)가 크기에 민감하거나 중요한 경우 효과를 볼 수 있다. \n",
    "    - 단점 : p와 q의 분포가 다르거나 범위가 다른 경우에 상관성을 놓침\n",
    "2. 코사인 유사도\n",
    "    - 문서간의 유사도를 계산\n",
    "    - 장점 : 벡터의 크기가 중요하지 않은 경우에 거리를 측정하기 위한 메트릭으로 사용\n",
    "        - 예) 문서 내에서 단어의 빈도수\n",
    "        -   문서들의 길이가 고르지 않더라도 문서내에서 얼마나 나왔는지라는 비율을 확인하기 때문에 상관없음\n",
    "    - 단점 : 벡터의 크기가 중요한 경우에 대해서 잘 작동하지 않음\n",
    "3. 피어슨 유사도\n",
    "    - 문서간의 유사도를 계산\n",
    "4. 자카드 유사도\n",
    "    - 문서간의 유사도를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. 자연어 처리 알고리즘 - TF-IDF\n",
    "- 참고 : https://wikidocs.net/31698\n",
    "1. 정의\n",
    "    - TF-IDF는 특정 문서 내에 특정 단어가 얼마나 자주 등장하는지를 의미하는 **단어 빈도(TF)**\n",
    "    -   전체 문서에서 특정 단어가 얼마나 자주 등장하는지를 의미하는 역문서 빈도(DF)\n",
    "    -   \"다른 문서에는 등장하지 않지만 특정 문서에서만 자주 등장하는 단어\"를 찾아서 문서 내 가중치를 계산하는 방법\n",
    "2. 용도 \n",
    "    - 문서의 핵심어를 추출, 문서들 사시의 유사도를 계산, 검색 결과의 중요도를 정하는 작업 등에 활용\n",
    "3. TF, DF, IDF 정의\n",
    "    - `TF`(d, t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
    "    - `DF`(t) : 특정 단어 t가 등장한 문서의 수\n",
    "    - `IDF`(d, t) : DF(t)에 반비례하는 수\n",
    "    - TF(d,t) * IDF(d,t) = TF-IDF(d,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2. TF-IDF를 사용하는 이유\n",
    "- 참고 : https://chan-lab.tistory.com/24\n",
    "1. Item이라는 컨텐츠를 벡터로 \"Feature Extract\" 과정을 수행해준다.\n",
    "2. 빈도수를 기반으로 많이 나오는 중요한 단어들을 잡아준다. => Counter Vectorizer\n",
    "3. Counter Vectorizer는 단순 빈도만을 계산\n",
    "    - 조사, 관사처럼 의미는 없지만 문장에 많이 등장하는 단어들도 높게 쳐주는 한계가 있음\n",
    "    - 이러한 단어들에는 패널티를 줘서 적절하게 중요한 단어만을 잡아내는 것이 TF-IDF 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Nomalizaion_datas(df):\n",
    "        # 훈련시킬 데이터와, 학습후 결과를 확인할 데이터 분리\n",
    "    df = df.loc[df['Date']<=\"2021\"]\n",
    "    df.sort_index(ascending=False).reset_index(drop=True)\n",
    "\n",
    "    #정규화하기\n",
    "    scaler = MinMaxScaler()\n",
    "    scale_cols = ['시가', '고가', '저가', '현재가', '거래량', '거래대금', 'D', 'G',\n",
    "        'O', 'Dow', 'kosdaq', 'nasdaq', 'S&P500']\n",
    "    df_scaled = scaler.fit_transform(df[scale_cols])\n",
    "    df_scaled = pd.DataFrame(df_scaled)\n",
    "    df_scaled.columns = scale_cols\n",
    "    \n",
    "    # 테스트사이즈, 윈도우사이즈 설정\n",
    "    TEST_SIZE = 200\n",
    "    WINDOW_SIZE = 20\n",
    "\n",
    "    #--------------------------------------------------------\n",
    "    train = df_scaled[:-TEST_SIZE]\n",
    "    test = df_scaled[-TEST_SIZE:]\n",
    "\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return  train, test\n",
    "\n",
    "\n",
    "def make_dataset(data, label, window_size=20):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(label.iloc[i+window_size]))\n",
    "    \n",
    "    return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "\n",
    " \n",
    "def training_target(train):\n",
    "    \n",
    "    feature_cols = ['시가', '고가', '저가', '거래량', '거래대금', 'D', 'G',\n",
    "            'O', 'kosdaq']\n",
    "    label_cols = ['현재가']\n",
    "\n",
    "    train_feature = train[feature_cols]\n",
    "    train_label = train[label_cols]\n",
    "\n",
    "    train_feature, train_label = make_dataset(train_feature, train_label, 20)\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)\n",
    "    \n",
    "    return x_train, x_valid, y_train, y_valid, feature_cols, label_cols, train_feature, train_label\n",
    "\n",
    "  \n",
    "def test_feature_label(feature_cols, label_cols):\n",
    "    test_feature = test[feature_cols]\n",
    "    test_label = test[label_cols]\n",
    "\n",
    "    X_test, y_test = make_dataset(test_feature, test_label, 20)\n",
    "    \n",
    "    return X_test, y_test, test_feature, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as test_feature\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM , Conv1D, Dropout, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_bulider(hp):\n",
    "    model = Sequential()\n",
    "    # 첫번째 층에 있는 유닛 수 조정하기\n",
    "    hp_unit1 = hp.Int(\"units1\", min_value = 32, max_value = 512, step=32)\n",
    "    hp_unit2 = hp.Int(\"units2\", min_value = 32, max_value = 512, step=32)\n",
    "    hp_unit3 = hp.Int(\"units3\", min_value = 32, max_value = 512, step=32)\n",
    "    hp_unit4 = hp.Int(\"units4\", min_value = 32, max_value = 512, step=32)\n",
    "    model.add(GRU(units = hp_unit1, \n",
    "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=True))\n",
    "    model.add(GRU(units = hp_unit2,\n",
    "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
    "               activation='relu', \n",
    "               return_sequences=True))\n",
    "    model.add(GRU(units = hp_unit3,  \n",
    "               activation='relu', \n",
    "               return_sequences=True))\n",
    "    model.add(LSTM(units = hp_unit4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='relu',))\n",
    "\n",
    "    # 학습속도 조정하기\n",
    "    #0.01, 0.001, 0.0001 ~ 0.05, 0.005, 0.0005\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4, 2e-2, 2e-3, 2e-4, 3e-2, 3e-3, 3e-4, 4e-2, 4e-3, 4e-4, 5e-2, 5e-3, 5e-4])\n",
    "    optimizer_2 = Adam(learning_rate= hp_learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer_2, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_kosdaq_price_OGD/'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0GST.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0GST.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0덕산네오룩스.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0덕산네오룩스.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0동진쌔미캠.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0동진쌔미캠.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0리노공업.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0리노공업.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0에프에스티.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0에프에스티.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0오션브릿지.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0오션브릿지.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0월덱스.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0월덱스.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0유니셈.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0유니셈.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0코미코.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0코미코.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0코세스.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0코세스.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0테스나.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0테스나.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0티씨케이.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0티씨케이.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Oracle from existing project my_dir_0하나머티리얼즈.xlsx.xlsx/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir_0하나머티리얼즈.xlsx.xlsx/intro_to_kt/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = open('2번째.txt', 'w')\n",
    "for i in file_list_py:\n",
    "    df = pd.read_excel(path + i)\n",
    "  \n",
    "    train, test= Nomalizaion_datas(df)\n",
    "    x_train, x_valid, y_train, y_valid, feature_cols, label_cols, train_feature, train_label = training_target(train)\n",
    "    X_test, y_test, test_feature, test_label = test_feature_label(feature_cols, label_cols)\n",
    "    tuner = kt.Hyperband(model_bulider,\n",
    "                     objective = \"val_accuracy\",\n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = f\"my_dir_0{i}\",\n",
    "                     project_name = \"intro_to_kt\")\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        tuner.search(x_train, y_train, epochs= 5, validation_data = (x_valid, y_valid))\n",
    "        best_hps =tuner.get_best_hyperparameters(num_trials= 1)[0]\n",
    "        print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "        print(f\"파일명: {i}\", \"최적 유닛수1 : {}, 최적 유닛수2 : {}, 최적 유닛수3 : {}, 최적 유닛수4 : {}, 최적 학습속도 : {}\".format(best_hps.get(\"units1\"), best_hps.get(\"units2\"), best_hps.get(\"units3\"), best_hps.get(\"units4\"), best_hps.get(\"learning_rate\")))\n",
    "        # globals()[\"model\" + i] = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTraingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일명: 하나머티리얼즈.xlsx.xlsx 최적 유닛수1 : 416, 최적 유닛수2 : 352, 최적 유닛수3 : 448, 최적 유닛수4 : 480, 최적 학습속도 : 0.02\n"
     ]
    }
   ],
   "source": [
    "print(f\"파일명: {i}\", \"최적 유닛수1 : {}, 최적 유닛수2 : {}, 최적 유닛수3 : {}, 최적 유닛수4 : {}, 최적 학습속도 : {}\".format(best_hps.get(\"units1\"), best_hps.get(\"units2\"), best_hps.get(\"units3\"), best_hps.get(\"units4\"), best_hps.get(\"learning_rate\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 20, 416)           532896    \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 20, 352)           813120    \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 20, 448)           1077888   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 480)               1783680   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 481       \n",
      "=================================================================\n",
      "Total params: 4,208,065\n",
      "Trainable params: 4,208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1dd6878eadd16a123e524e58bdb31afc5a459331ac6b46884eb5fc41d9222cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
